### **Iterative class discovery and feature selection using Minimal Spanning Trees**

**Авторы:** Sudhir Varma, Richard Simon  
**Источники:** Научная статья (BMC Bioinformatics, 2004) и презентация.

---

#### **1. Проблема и Цель**

**Проблема:**
- При кластеризации образцов (например, пациентов) по данным экспрессии генов обычно используются **все гены**.
- В данных много «шумных» генов, которые не несут полезной информации.
- Сигнал от небольшой группы информативных генов **теряется на фоне шума**, что мешает обнаружить реальные биологические классы (например, подтипы рака).

**Цель:**
Разработать алгоритм, который:
- Обнаруживает **скрытые классы образцов**, видимые только на подмножестве генов.
- Итеративно **совмещает кластеризацию и отбор признаков** (генов).
- Находит несколько **бинарных разбиений** и наборы генов, их поддерживающих.

---

#### **2. Ключевые Компоненты Алгоритма**

##### **2.1. Минимальное Остовное Дерево (MST)**
- **MST** – это дерево, соединяющее все точки (образцы) с минимальной суммой длин рёбер.
- **Идея:** Удаление ребра из MST даёт **бинарное разбиение** выборки на два кластера.
- **Преимущество:** Вместо перебора всех возможных разбиений (2^(N-1)-1) алгоритм рассматривает только **N-1** разбиение (по числу рёбер в MST).
- Удаление ребра длины **δ** гарантирует, что кластеры разделены как минимум на **δ**.

##### **2.2. Метрика кластеризации: Fukuyama-Sugeno (F-S)**
Формула для оценки качества разбиения:

\[ FS(S) = \sum_{k=1}^2 \sum_{j=1}^{N_k} \left[ \left\| x_j^k - \mu_k \right\|^2 - \left\| \mu_k - \mu \right\|^2 \right] \]

- Чем **меньше** значение FS, тем лучше: кластеры плотные и далеко друг от друга.

##### **2.3. Отбор признаков (генов)**
- Для каждого найденного разбиения вычисляется **t-статистика** для каждого гена между двумя кластерами.
- Гены с |t-статистикой| > **T_thresh** считаются значимыми для этого разбиения.
- **T_thresh** вычисляется на основе параметра **P_thresh** – перцентиля t-распределения.

---

#### **3. Алгоритм (Итеративная процедура)**

**Входные параметры:**
- `MaxNp` – максимальное число разбиений
- `P_thresh` – порог для отбора генов
- `X_sg` – матрица экспрессии (образцы × гены)

**Шаги:**

1. **Инициализация:** `Fset = {все гены}`, `Np = 0`
2. **Пока** `Np < MaxNp`:
   - `F = Fset`
   - `t = T_thresh / 2`
   - **Пока** (истина):
     - Строим **MST** на генах из `F`
     - Для каждого ребра MST вычисляем **F-S меру**
     - Выбираем разбиение **P*** с **наименьшим FS**
     - Для каждого гена в `F` вычисляем t-статистику
     - Формируем новый набор генов: `F_new = {гены с |t| > t}`
     - **Если** `F_new == F` **и** `t == T_thresh`:
       - Выводим **P*** и **F**
       - Удаляем гены `F` из `Fset`
       - `Np += 1`
       - Выходим из внутреннего цикла
     - **Иначе**:
       - `F = F_new`
       - Увеличиваем `t` (ужесточаем порог)

---

#### **4. Результаты и Сравнения**

##### **4.1. Синтетические данные**
- Алгоритм **лучше обнаруживает искусственно заложенные кластеры**, чем иерархическая кластеризация.
- **Низкая вероятность ложных срабатываний** (~0.01).
- Для обнаружения кластеров требуется **в 4 раза меньше генов**, чем при иерархической кластеризации.

##### **4.2. Реальные данные (микроматрицы)**

**BRCA данные (гены BRCA1/BRCA2):**
- Кластеризация по всем генам **не разделяет** BRCA1 и BRCA2.
- Алгоритм нашёл разбиение (**Partition 4**), которое разделяет BRCA1 и BRCA2 с **1 ошибкой**, используя всего **61 ген**.

**Leukemia данные (AML/ALL):**
- Первое разбиение почти идеально отделяет **AML** от **ALL** (1 ошибка в каждом кластере).
- Гены, найденные на обучающей выборке, успешно разделили тестовую выборку.

**Lymphoma данные (DLBCL):**
- Алгоритм обнаружил разделение на **GC B-like** и **Activated B-like** подтипы.

##### **4.3. Сравнение с другими методами**
- **Overabundance Analysis (Ben-Dor):** Полный перебор (дорого), хуже Jaccard index.
- **CLIFF (Xing & Karp):** Нормализованный разрез графа, но уступает в точности.
- **Gene Shaving (Hastie):** Кластеризует гены, а не образцы.

---

#### **5. Слабые Стороны Метода (Varma & Simon)**
- Требует **ручной настройки параметров** (P_thresh, метрика расстояния).
- Работает **только с бинарными разбиениями**.
- **t-тест** может быть нестабилен при малом числе образцов.

---

#### **6. Современные Альтернативы (Упомянуты в презентации)**

##### **6.1. Sparse K-means (Witten & Tibshirani, 2010)**
- **Встроенный отбор признаков** через L1-регуляризацию.
- **Автоматический подбор параметров** (через перестановочные тесты).
- Работает с **K кластерами одновременно** (не только бинарными).

##### **6.2. Seurat (Stuart et al., 2019)**
- Предназначен для **single-cell RNA-seq**.
- Использует **PCA**, **k-NN графы**, **Louvain/Leiden** кластеризацию.
- **GLM-модели** для поиска маркерных генов.
- Устойчив к шуму и работает с большими данными.

---

#### **7. Выводы**

- Предложенный алгоритм **эффективно сочетает кластеризацию и отбор признаков**.
- Позволяет находить **биологически значимые классы**, невидимые при использовании всех генов.
- **Гибкость:** Можно настроить `P_thresh` для поиска либо сильно выраженных, но редких, либо слабых, но многочисленных сигналов.
- **Интерпретируемость:** Каждое разбиение сопровождается списком значимых генов для последующего биологического анализа.

---

**Заключение:**  
Метод Varma & Simon стал важным шагом в развитии методов кластеризации с отбором признаков. Несмотря на появление более современных методов (Sparse K-means, Seurat), его идеи остаются актуальными и illustrative для понимания проблем и решений в биоинформатике.
